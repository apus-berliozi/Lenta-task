#Я взял на себя смелость подойти к ситуации с другой стороны. Из моего личного опыта, является возможность выгрузить определённый пулл данных через API запрос (в нашем случае - выгрузить инфу об всех товарах конкретного магазина), поэтому я пытался узнать у коллег из ленты конкретную ссылку запроса, но увы, не получил ответ. В данном коде я исхожу из возможности выгружать всю информацию за раз, если это по какой-либо причине не является возможным, пожалуйста проинформируйте меня, буду переписывать.
#Я видел потенциально две большие проблемы: 
# 1 - Так как пулл данных будет очень большим (полагаю больше тридцати тысяч товаров в одном запросе), обработка его в виде листа загружала бы память слишком сильно. Поэтому я своём коде я перевёл его в генератор. Данный опционал питона позволяет нам обрабатывать большие объёмы данных без потери в производительности.
# 2 - Учитывая что у нас имеется десятки тысяч штрихкодов, посследовательная загрузка в базу данных занимала бы много времени (особено если БД находится на другом сервере, и нам было бы необходимо ждать ответа от него). Я использовал библиотеку asyncio для решения этой проблемы. Как вы увидите из кода, пока мы ожидаем ответ по одному запросу в MySQL, будет отправляться второй, третий, и тд. Это поможет нам существенно ускорить процесс передачи информации. Я также учёл тот факт, что нам не все этапы нужно проводить асинхронно, поэтому использовал функцию asyncio.run(), чтобы выполнять асинхронно локальный участок кода.
# В целом можно также добавить обратную связь - чтобы в случае ошибок клиент понимал что конкретно пошёл не так. Я сделал это с API запросами, чтобы в случае неудачного запроса выдавался код ошибки (404, 401 и тд.). Можно также в конце вывести общую информацию, что для магазинов с таким-то кодом всё загрузилось, в то время как запросы для магазинов с другим кодом - не обработались.
# Далее привожу код целиком:

#1 - Импортируем все необходимые нам модули
import json #Для обработки результата запроса
import requests #Для выполнения запроса
import asyncio #Для выполнения асинхронной части кода
import mysql.connector #Для подключения к базе данных
import time #Для паузы запроса к ленте, в случае если ответ придёт быстрее чем за 2 секунды

#2 - Задаём необходимые нам функции

def getBarcodesLenta(): #Достаём необходимые нам штрих-коды. Не вижу особого смысла делать эту функцию асинхронной, так как данные мы получаем один раз
    barcodes = await db().fetch("""
    select distinct barcode
    from competitor.track_barcodes
    where competitor_name = 'лента')
    order by pb.barcode""")
    return barcodes #Честно говоря, я бы преобразовал данный элемент в множество (set). Мне кажется, что это будет более эфективно, так как компьютеру не нужно будет помнить какой порядок у какого элемента - просто какие элементы есть. Для целей моего кода вполне подходит, плюс учитывая сколько у нас этих баркодов, вполне подходит
async def Vnesenie_dannix_v_SQL(t):  #Задаём функцию, которая будет вносить информацию об одном продукте в базу данных
    if t['barcode'] in barcodes: #Проверяем есть ли в ответе с сайта нужный нам штрих код
        insert_new_data = ("INSERT INTO statistica (store_code, barcode, date, sku, price)" f"VALUES, {store['store_code']}, {t['barcode']}, CURRENT_DATE, {t['sku']}, {t['price']}") 
        await curA.execute(insert_new_data)
        await MySQLbaza.commit()
async def Upravlenie_vneseniem_dannix(): #Мы задаём данную функцию для управления функцией Vnesenie_dannix_v_SQL. Таким образом, пока идёт ответ от сервера MySQL по одному запросу, мы можем направить массу других чтобы сэкономить время.
    tasks = [asyncio_ensure_future(Vnesenie_dannix_v_SQL(t) for t in generator]
    await asyncio.wait(tasks)
getBarcodesLenta() #Получаем штрихкоды
stores = [{'id': '1', 'store_code': '0809'},{'id': '2', 'store_code': '0099'}]  #Задаём список магазинов из которых будем брать код магазина, и подставлять его в поисковую строку
MySQLbaza = mysql.connector.connect(user = 'Roman', database = 'Test') #Я исходил из того, что уже существует база данных в которую будет записываться результат. Так как я работал с MySQL, выбрал её. 
curA = MySQLbaza.cursor(buffered=True)#Этим будет осуществляться внесение информации в базу данных

for store in stores: #С помощью цикла for делаем запрос для всех магазинов из списка
    start_time = time.time() #Логирую начало запроса
    generator = requests.get(f"https://lenta.com/api/v1/stores/{store['store_code']}/product/") #Не вижу особого смысла делать данный запрос асинхронным. Нам по-сути нужно выгрузить один большой ответ, и быстро его обработать. Полагаю что сам запрос будет выгружаться довольно дольше (возможно даже больше двух секунд), но на всякий случай вставил проверку по времени
    if generator.status_code != 200:
        print(f'Запрос для магазина {store} выполнился с ошибкой {generator.status_code}. Данные для этого магазина не были загружены с официального сайта Ленты'}) #На случай ошибки - выскочит данная плашка, чтобы было понятно что происходит
    else:
        end_time = start_time - time.time() #Ограничение на случай если запрос выполнился меньше чем за две секунды
        if -(end_time) < 2:
            time.sleep(-end_time)
            generator = (n for n in  json.loads(generator.text)) #Мы превращаем огромный список товаров в генератор, что позволит нам эффективно его обработать в цикле for
        else:
            generator = (n for n in  json.loads(generator.text))
        asyncio.run(Upravlenie_vneseniem_dannix())
        print(f"Загрузка в базу данных для магазина {store} прошла успешно!")
print("Процесс внесения информации в базу данных завершён!"）
MySQLbaza.close()